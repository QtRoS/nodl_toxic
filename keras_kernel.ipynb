{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 9)\n",
    "sns.set(context='paper', style='darkgrid', rc={'figure.facecolor':'white'}, font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout, GRU, LeakyReLU\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 24000  # TODO\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"input/train.csv\")\n",
    "test = pd.read_csv(\"input/test.csv\")\n",
    "train = train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentences_train = train[\"comment_text\"].fillna(\"CVxTz\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"CVxTz\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path=\"weights_base.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor='val_loss', mode='min', patience=20)\n",
    "callbacks = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, output_dim=128)(inp)\n",
    "    x = Bidirectional(LSTM(50, return_sequences=True))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation='relu')(x)  # Leaky relu?\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(6, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer='nadam', # adam\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86265 samples, validate on 9586 samples\n",
      "Epoch 1/2\n",
      "86240/86265 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9789Epoch 00001: val_loss did not improve\n",
      "86265/86265 [==============================] - 523s 6ms/step - loss: 0.0634 - acc: 0.9790 - val_loss: 0.0519 - val_acc: 0.9809\n",
      "Epoch 2/2\n",
      "86240/86265 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9831Epoch 00002: val_loss did not improve\n",
      "86265/86265 [==============================] - 511s 6ms/step - loss: 0.0448 - acc: 0.9831 - val_loss: 0.0518 - val_acc: 0.9811\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "history = model.fit(X_t, y, batch_size=32, epochs=2, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(file_path)\n",
    "y_test = model.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = y_test\n",
    "sample_submission.to_csv(\"output/keras_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_with_params(p):\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, output_dim=p['embedding_size'])(inp)\n",
    "    if p['cell_type']=='lstm':\n",
    "        cell = LSTM(int(p['units']), return_sequences=True, dropout=p['dropout_r'], recurrent_dropout=p['dropout_r'])\n",
    "    else:\n",
    "        cell = GRU(int(p['units']), return_sequences=True, dropout=p['dropout_r'], recurrent_dropout=p['dropout_r'])\n",
    "    x = Bidirectional(cell)(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(p['dropout_1'])(x)\n",
    "    x = Dense(p['dense_1'])(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(p['dropout_2'])(x)\n",
    "    x = Dense(6, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=p['opt_algo'], metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "def score(p):\n",
    "    print(\"Training with params:\", p)\n",
    "    model = get_model_with_params(p)\n",
    "    h = model.fit(X_t, y, batch_size=p['batch_size'], epochs=p['epochs'], validation_split=0.1, callbacks=callbacks)\n",
    "    score = min(h.history['val_loss']) #h.history['val_loss'][-1]\n",
    "    print(\"\\tScore {0}\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "def optimize():\n",
    "    trials = Trials()\n",
    "    space = {\n",
    "        'batch_size' : hp.choice('batch_size', np.arange(12, 25, dtype=int)),\n",
    "        'dropout_1': hp.quniform('dropout_1', 0.00, 0.15, 0.025),\n",
    "        'dropout_2': hp.quniform('dropout_2', 0.025, 0.2, 0.025),\n",
    "        'dropout_r': 0, # hp.quniform('dropout_r', 0.00, 0.15, 0.025),\n",
    "        'dense_1': hp.choice('dense_1', np.arange(40, 65, dtype=int)),\n",
    "        'cell_type': hp.choice('cell_type', ['lstm', 'gru']),\n",
    "        'embedding_size': hp.choice('embedding_size', np.arange(64, 81, dtype=int)), # [64, 96, 128]\n",
    "        'units': hp.choice('units', np.arange(32, 48, dtype=int)),\n",
    "        'opt_algo': hp.choice('opt_algo', ['rmsprop', 'nadam', 'adam']),\n",
    "        'epochs': 2,\n",
    "    }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=16)\n",
    "\n",
    "    print(\"Best:\", best)\n",
    "    return best, trials\n",
    "\n",
    "b, t = optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 100, 64)           1536000   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 100, 48)           17088     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 60)                2940      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 6)                 366       \n",
      "=================================================================\n",
      "Total params: 1,556,394\n",
      "Trainable params: 1,556,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 86265 samples, validate on 9586 samples\n",
      "Epoch 1/2\n",
      "86260/86265 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9766Epoch 00001: val_loss did not improve\n",
      "86265/86265 [==============================] - 383s 4ms/step - loss: 0.0733 - acc: 0.9766 - val_loss: 0.0526 - val_acc: 0.9811\n",
      "Epoch 2/2\n",
      "86260/86265 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9824Epoch 00002: val_loss did not improve\n",
      "86265/86265 [==============================] - 384s 4ms/step - loss: 0.0475 - acc: 0.9824 - val_loss: 0.0514 - val_acc: 0.9816\n"
     ]
    }
   ],
   "source": [
    "p = {'cell_type': 'lstm', 'opt_algo': 'adam', 'units': 24, 'batch_size': 20, 'embedding_size': 128,  \n",
    "     'dense_1': 60, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_r': 0.0, 'epochs': 2}\n",
    "manual_model = get_model_with_params(p)\n",
    "manual_model.summary()\n",
    "h = manual_model.fit(X_t, y, batch_size=p['batch_size'], epochs=p['epochs'], validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 100, 128)          3072000   \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 100, 100)          53700     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 51)                5151      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 312       \n",
      "=================================================================\n",
      "Total params: 3,131,163\n",
      "Trainable params: 3,131,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = load_model(file_path, custom_objects={ })\n",
    "final_model.summary()\n",
    "y_test = final_model.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = y_test\n",
    "sample_submission.to_csv(\"output/keras_tuned_0.0457.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plots\n",
    "# my_plots = ['loss', 'acc']\n",
    "# for plot in my_plots:\n",
    "#     plt.plot(history.history[plot])\n",
    "#     plt.plot(history.history['val_' + plot])\n",
    "#     plt.title('model ' + plot)\n",
    "#     plt.ylabel(plot)\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.legend(['train', 'test'], loc='upper left')\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
